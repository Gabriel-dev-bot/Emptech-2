{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyON5KYD4EuEg0wXOf34mKcE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gabriel-dev-bot/Emptech-2/blob/main/Hands_on_Activity_8_1_Saving_Models_Pabilan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name: Pabilan, Gabriel G.\n",
        "\n",
        "Course and Section: CPE019-CPE32S1\n",
        "\n",
        "Date of Submission: 07/08/2024\n",
        "\n",
        "Instructor: Engr. Roman Richard"
      ],
      "metadata": {
        "id": "Zn1AX_8SucaL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explain your datasets and the problem being addressed.\n",
        "\n",
        "This activity uses a classification dataset. It spots real websites and fake ones trying to steal info. Cybersecurity pros deal with this problem all the time. Bad guys make fake sites to trick people. They want your passwords, credit cards, and personal stuff. It's a sneaky game of cat and mouse online."
      ],
      "metadata": {
        "id": "FbB3OvXWucvI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38l4zRf1QRgG",
        "outputId": "4c9be2c2-7e12-4c86-c77c-5e17c0b58cea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2.0.3)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2024.6.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ],
      "source": [
        "pip install ucimlrepo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "pima_indians_diabetes = fetch_ucirepo(id=159)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = pima_indians_diabetes.data.features\n",
        "y = pima_indians_diabetes.data.targets\n",
        "\n",
        "# metadata\n",
        "print(pima_indians_diabetes.metadata)\n",
        "\n",
        "# variable information\n",
        "print(pima_indians_diabetes.variables)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgEIoTIHQ2VD",
        "outputId": "aecb4f96-c13f-40bc-892a-b17228ef6f9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'uci_id': 159, 'name': 'MAGIC Gamma Telescope', 'repository_url': 'https://archive.ics.uci.edu/dataset/159/magic+gamma+telescope', 'data_url': 'https://archive.ics.uci.edu/static/public/159/data.csv', 'abstract': 'Data are MC generated to simulate registration of high energy gamma particles in an atmospheric Cherenkov telescope', 'area': 'Physics and Chemistry', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 19020, 'num_features': 10, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2004, 'last_updated': 'Tue Dec 19 2023', 'dataset_doi': '10.24432/C52C8B', 'creators': ['R. Bock'], 'intro_paper': None, 'additional_info': {'summary': \"The data are MC generated (see below) to simulate registration of high energy gamma particles in a ground-based atmospheric Cherenkov gamma telescope using the imaging technique. Cherenkov gamma telescope observes high energy gamma rays, taking advantage of the radiation emitted by charged particles produced inside the electromagnetic showers initiated by the gammas, and developing in the atmosphere. This Cherenkov radiation (of visible to UV wavelengths) leaks through the atmosphere and gets recorded in the detector, allowing reconstruction of the shower parameters. The available information consists of pulses left by the incoming Cherenkov photons on the photomultiplier tubes, arranged in a plane, the camera. Depending on the energy of the primary gamma, a total of few hundreds to some 10000 Cherenkov photons get collected, in patterns (called the shower image), allowing to discriminate statistically those caused by primary gammas (signal) from the images of hadronic showers initiated by cosmic rays in the upper atmosphere (background).\\r\\n\\r\\nTypically, the image of a shower after some pre-processing is an elongated cluster. Its long axis is oriented towards the camera center if the shower axis is parallel to the telescope's optical axis, i.e. if the telescope axis is directed towards a point source. A principal component analysis is performed in the camera plane, which results in a correlation axis and defines an ellipse. If the depositions were distributed as a bivariate Gaussian, this would be an equidensity ellipse. The characteristic parameters of this ellipse (often called Hillas parameters) are among the image parameters that can be used for discrimination. The energy depositions are typically asymmetric along the major axis, and this asymmetry can also be used in discrimination. There are, in addition, further discriminating characteristics, like the extent of the cluster in the image plane, or the total sum of depositions.\\r\\n\\r\\nThe data set was generated by a Monte Carlo program, Corsika, described in:\\r\\n    D. Heck et al., CORSIKA, A Monte Carlo code to simulate extensive air showers,\\r\\n    Forschungszentrum Karlsruhe FZKA 6019 (1998).\\r\\nhttp://rexa.info/paper?id=ac6e674e9af20979b23d3ed4521f1570765e8d68\\r\\n\\r\\nThe program was run with parameters allowing to observe events with energies down to below 50 GeV.\", 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': '    1.  fLength:  continuous  # major axis of ellipse [mm]\\r\\n    2.  fWidth:   continuous  # minor axis of ellipse [mm] \\r\\n    3.  fSize:    continuous  # 10-log of sum of content of all pixels [in #phot]\\r\\n    4.  fConc:    continuous  # ratio of sum of two highest pixels over fSize  [ratio]\\r\\n    5.  fConc1:   continuous  # ratio of highest pixel over fSize  [ratio]\\r\\n    6.  fAsym:    continuous  # distance from highest pixel to center, projected onto major axis [mm]\\r\\n    7.  fM3Long:  continuous  # 3rd root of third moment along major axis  [mm] \\r\\n    8.  fM3Trans: continuous  # 3rd root of third moment along minor axis  [mm]\\r\\n    9.  fAlpha:   continuous  # angle of major axis with vector to origin [deg]\\r\\n   10.  fDist:    continuous  # distance from origin to center of ellipse [mm]\\r\\n   11.  class:    g,h         # gamma (signal), hadron (background)\\r\\n\\r\\n   g = gamma (signal):     12332\\r\\n   h = hadron (background): 6688\\r\\n\\r\\n   For technical reasons, the number of h events is underestimated. In the real data, the h class represents the majority of the events.\\r\\n\\r\\n   The simple classification accuracy is not meaningful for this data, since classifying a background event as signal is worse than classifying a signal event as background. For comparison of different classifiers an ROC curve has to be used. The relevant points on this curve are those, where the probability of accepting a background event as signal is below one of the following thresholds: 0.01, 0.02, 0.05, 0.1, 0.2 depending on the required quality of the sample of the accepted events for different experiments.', 'citation': None}}\n",
            "        name     role        type demographic  \\\n",
            "0    fLength  Feature  Continuous        None   \n",
            "1     fWidth  Feature  Continuous        None   \n",
            "2      fSize  Feature  Continuous        None   \n",
            "3      fConc  Feature  Continuous        None   \n",
            "4     fConc1  Feature  Continuous        None   \n",
            "5      fAsym  Feature  Continuous        None   \n",
            "6    fM3Long  Feature  Continuous        None   \n",
            "7   fM3Trans  Feature  Continuous        None   \n",
            "8     fAlpha  Feature  Continuous        None   \n",
            "9      fDist  Feature  Continuous        None   \n",
            "10     class   Target      Binary        None   \n",
            "\n",
            "                                          description  units missing_values  \n",
            "0                               major axis of ellipse     mm             no  \n",
            "1                               minor axis of ellipse     mm             no  \n",
            "2              10-log of sum of content of all pixels  #phot             no  \n",
            "3       ratio of sum of two highest pixels over fSize   None             no  \n",
            "4                   ratio of highest pixel over fSize   None             no  \n",
            "5   distance from highest pixel to center, project...   None             no  \n",
            "6           3rd root of third moment along major axis     mm             no  \n",
            "7           3rd root of third moment along minor axis     mm             no  \n",
            "8           angle of major axis with vector to origin    deg             no  \n",
            "9           distance from origin to center of ellipse     mm             no  \n",
            "10                gamma (signal), hadron (background)   None             no  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save a model in HDF5 format:"
      ],
      "metadata": {
        "id": "Q6sPzxrPV15L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP for Pima Indians Dataset Save to HDF5\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import numpy\n",
        "import os\n",
        "import pandas as pd\n",
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)\n",
        "# load pima indians dataset\n",
        "dataset = pd.read_csv(\"https://archive.ics.uci.edu/static/public/379/data.csv\", delimiter=\",\")\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset.iloc[:,0:8]\n",
        "Y = dataset.iloc[:,8]\n",
        "\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=(8,), activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# Fit the model\n",
        "model.fit(X, Y, epochs=50, batch_size=128, verbose=0)\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X, Y, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "\n",
        "# save model to HDF5\n",
        "model.save(\"pima_indians_diabetes_model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EABicW8UTMFa",
        "outputId": "e510ac71-1ab4-48d0-ee90-9cf8c651eb39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 90.98%\n",
            "Saved model to disk\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP for Pima Indians Dataset Save to HDF5\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import numpy\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "# load pima indians dataset\n",
        "dataset = pd.read_csv(\"https://archive.ics.uci.edu/static/public/379/data.csv\", delimiter=\",\")\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset.iloc[:,0:8]\n",
        "Y = dataset.iloc[:,8]\n",
        "\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# Fit the model\n",
        "model.fit(X, Y, epochs=150, batch_size=10, verbose=0)\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X, Y, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "\n",
        "# save model to HDF5\n",
        "model.save(\"pima_indians_diabetes_model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtjaK4iYTbJk",
        "outputId": "f5618212-6db8-4b27-f609-e932bfa8aa95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 90.61%\n",
            "Saved model to disk\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# serialize model to YAML\n",
        "model_yaml = model.to_json()\n",
        "with open(\"pima_indians_diabetes_model.yaml\", \"w\") as yaml_file:\n",
        "    yaml_file.write(model_yaml)"
      ],
      "metadata": {
        "id": "uBYcPvPMXTUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "# Read the contents of the YAML file\n",
        "with open('pima_indians_diabetes_model.yaml', 'r') as yaml_file:\n",
        "    model_yaml_content = yaml.safe_load(yaml_file)\n",
        "\n",
        "# Print the parsed YAML content with indentation\n",
        "print(yaml.dump(model_yaml_content, indent=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3qNYlICWNMI",
        "outputId": "20ed8232-7e07-4ca6-e418-3914c31a899d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "backend: tensorflow\n",
            "class_name: Sequential\n",
            "config:\n",
            "    layers:\n",
            "    -   class_name: InputLayer\n",
            "        config:\n",
            "            batch_input_shape:\n",
            "            - null\n",
            "            - 8\n",
            "            dtype: float32\n",
            "            name: dense_4_input\n",
            "            ragged: false\n",
            "            sparse: false\n",
            "        module: keras.layers\n",
            "        registered_name: null\n",
            "    -   build_config:\n",
            "            input_shape:\n",
            "            - null\n",
            "            - 8\n",
            "        class_name: Dense\n",
            "        config:\n",
            "            activation: relu\n",
            "            activity_regularizer: null\n",
            "            batch_input_shape:\n",
            "            - null\n",
            "            - 8\n",
            "            bias_constraint: null\n",
            "            bias_initializer:\n",
            "                class_name: Zeros\n",
            "                config: {}\n",
            "                module: keras.initializers\n",
            "                registered_name: null\n",
            "            bias_regularizer: null\n",
            "            dtype: float32\n",
            "            kernel_constraint: null\n",
            "            kernel_initializer:\n",
            "                class_name: GlorotUniform\n",
            "                config:\n",
            "                    seed: null\n",
            "                module: keras.initializers\n",
            "                registered_name: null\n",
            "            kernel_regularizer: null\n",
            "            name: dense_4\n",
            "            trainable: true\n",
            "            units: 12\n",
            "            use_bias: true\n",
            "        module: keras.layers\n",
            "        registered_name: null\n",
            "    -   build_config:\n",
            "            input_shape:\n",
            "            - null\n",
            "            - 12\n",
            "        class_name: Dense\n",
            "        config:\n",
            "            activation: relu\n",
            "            activity_regularizer: null\n",
            "            bias_constraint: null\n",
            "            bias_initializer:\n",
            "                class_name: Zeros\n",
            "                config: {}\n",
            "                module: keras.initializers\n",
            "                registered_name: null\n",
            "            bias_regularizer: null\n",
            "            dtype: float32\n",
            "            kernel_constraint: null\n",
            "            kernel_initializer:\n",
            "                class_name: GlorotUniform\n",
            "                config:\n",
            "                    seed: null\n",
            "                module: keras.initializers\n",
            "                registered_name: null\n",
            "            kernel_regularizer: null\n",
            "            name: dense_5\n",
            "            trainable: true\n",
            "            units: 8\n",
            "            use_bias: true\n",
            "        module: keras.layers\n",
            "        registered_name: null\n",
            "    -   build_config:\n",
            "            input_shape:\n",
            "            - null\n",
            "            - 8\n",
            "        class_name: Dense\n",
            "        config:\n",
            "            activation: sigmoid\n",
            "            activity_regularizer: null\n",
            "            bias_constraint: null\n",
            "            bias_initializer:\n",
            "                class_name: Zeros\n",
            "                config: {}\n",
            "                module: keras.initializers\n",
            "                registered_name: null\n",
            "            bias_regularizer: null\n",
            "            dtype: float32\n",
            "            kernel_constraint: null\n",
            "            kernel_initializer:\n",
            "                class_name: GlorotUniform\n",
            "                config:\n",
            "                    seed: null\n",
            "                module: keras.initializers\n",
            "                registered_name: null\n",
            "            kernel_regularizer: null\n",
            "            name: dense_6\n",
            "            trainable: true\n",
            "            units: 1\n",
            "            use_bias: true\n",
            "        module: keras.layers\n",
            "        registered_name: null\n",
            "    name: sequential_1\n",
            "keras_version: 2.15.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checkpoint Neural Network Model Improvements:"
      ],
      "metadata": {
        "id": "f_H96H6OXV9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checkpoint the weights when validation accuracy improves\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "seed = 42\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# load pima indians dataset\n",
        "dataset = pd.read_csv(\"https://archive.ics.uci.edu/static/public/379/data.csv\", delimiter=\",\")\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset.iloc[:,0:8]\n",
        "Y = dataset.iloc[:,8]\n",
        "\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=(8,), activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# checkpoint\n",
        "filepath=\"pima_indians_diabetes_weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X, Y, validation_split=0.33, epochs=150, batch_size=10, callbacks=callbacks_list, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94fVjuRoWtyM",
        "outputId": "bd23bb67-f864-47cd-d8ac-2ee24104d8ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.87919, saving model to pima_indians_diabetes_weights-improvement-01-0.88.hdf5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2: val_accuracy did not improve from 0.87919\n",
            "\n",
            "Epoch 3: val_accuracy did not improve from 0.87919\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.87919\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.87919\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.87919\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.87919\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.87919\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.87919\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.87919\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.87919\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.87919\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.87919\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.87919\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.87919\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.87919\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.87919\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.87919\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.87919\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.87919\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.87919\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.87919\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.87919\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.87919\n",
            "\n",
            "Epoch 25: val_accuracy improved from 0.87919 to 0.88367, saving model to pima_indians_diabetes_weights-improvement-25-0.88.hdf5\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 31: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 32: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 33: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 34: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 35: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 36: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 37: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 38: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 39: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 40: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 41: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 42: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 43: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 44: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 45: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 46: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 47: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 48: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 49: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 50: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 51: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 52: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 53: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 54: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 55: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 56: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 57: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 58: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 59: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 60: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 61: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 62: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 63: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 64: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 65: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 66: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 67: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 68: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 69: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 70: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 71: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 72: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 73: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 74: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 75: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 76: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 77: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 78: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 79: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 80: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 81: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 82: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 83: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 84: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 85: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 86: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 87: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 88: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 89: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 90: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 91: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 92: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 93: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 94: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 95: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 96: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 97: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 98: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 99: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 100: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 101: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 102: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 103: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 104: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 105: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 106: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 107: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 108: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 109: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 110: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 111: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 112: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 113: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 114: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 115: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 116: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 117: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 118: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 119: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 120: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 121: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 122: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 123: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 124: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 125: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 126: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 127: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 128: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 129: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 130: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 131: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 132: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 133: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 134: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 135: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 136: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 137: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 138: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 139: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 140: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 141: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 142: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 143: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 144: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 145: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 146: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 147: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 148: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 149: val_accuracy did not improve from 0.88367\n",
            "\n",
            "Epoch 150: val_accuracy did not improve from 0.88367\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7cbf726799c0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load a saved Neural Network model:"
      ],
      "metadata": {
        "id": "4_i70VjpX2nO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a saved Neural Network model\n",
        "from tensorflow.keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "import pandas as pd\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "# load model\n",
        "model = load_model(\"pima_indians_diabetes_model.h5\")\n",
        "print(\"Loaded model from disk\")\n",
        "\n",
        "# load pima indians dataset\n",
        "dataset = pd.read_csv(\"https://archive.ics.uci.edu/static/public/379/data.csv\", delimiter=\",\")\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset.iloc[:,0:8]\n",
        "Y = dataset.iloc[:,8]\n",
        "\n",
        "# estimate accuracy on whole dataset using loaded model\n",
        "scores = model.evaluate(X, Y, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmOo2-jXX3Gc",
        "outputId": "2a864836-0a22-40d8-e4e2-193f2e62e213"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded model from disk\n",
            "accuracy: 90.61%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load Pima Indians Diabetes dataset\n",
        "dataset = pd.read_csv(\"https://archive.ics.uci.edu/static/public/379/data.csv\", delimiter=\",\")\n",
        "\n",
        "# Split into input (X) and output (Y) variables\n",
        "X = dataset.iloc[:,0:8]\n",
        "Y = dataset.iloc[:,8]\n",
        "\n",
        "# Create model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=8, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit(X, Y, validation_split=0.44, epochs=100, batch_size=512, verbose=0)\n",
        "\n",
        "# List all data in history\n",
        "print(history.history.keys())\n",
        "\n",
        "# Summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 944
        },
        "id": "9rdHwkVOeP9f",
        "outputId": "d5392e80-9eb0-4f7d-9f81-292921404db5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show the application of Dropout Regularization:"
      ],
      "metadata": {
        "id": "cM52Bd30eaZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikeras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wo7PiH7JeXco",
        "outputId": "d1085bed-aa33-4540-86d9-d772c1595070"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikeras in /usr/local/lib/python3.10/dist-packages (0.13.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from scikeras) (3.4.1)\n",
            "Requirement already satisfied: scikit-learn>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from scikeras) (1.5.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.25.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (3.9.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (24.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras>=3.2.0->scikeras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import read_csv\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Load the dataset\n",
        "dataframe = read_csv(\"https://archive.ics.uci.edu/static/public/379/data.csv\")\n",
        "dataset = dataframe.values\n",
        "\n",
        "# Split the dataset into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8].astype(float)\n",
        "Y = dataset[:,8]\n",
        "\n",
        "# Encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "encoded_Y = encoder.transform(Y)\n",
        "\n",
        "# Define the baseline model\n",
        "def create_baseline():\n",
        "    # Create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, input_dim=8, activation='relu'))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compile model\n",
        "    sgd = SGD(learning_rate=0.01, momentum=0.8)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create a pipeline for standardization and model training\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=50, batch_size=64, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "\n",
        "# Evaluate the model using cross-validation\n",
        "results = cross_val_score(pipeline, X, encoded_Y, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42))\n",
        "\n",
        "# Print the mean and standard deviation of the accuracy scores\n",
        "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean() * 100, results.std() * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDHEAnDJe7er",
        "outputId": "203b0fd6-c06b-4b0f-edaa-dc5687d23f93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline: 88.17% (0.56%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show the application of Dropout on the visible layer:"
      ],
      "metadata": {
        "id": "saifCSZ8o7x2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import read_csv\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# load dataset\n",
        "dataframe = read_csv(\"https://archive.ics.uci.edu/static/public/379/data.csv\")\n",
        "dataset = dataframe.values\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:, 0:8].astype(float)\n",
        "Y = dataset[:, 8]\n",
        "\n",
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "encoded_Y = encoder.transform(Y)\n",
        "\n",
        "# dropout in the input layer with weight constraint\n",
        "def create_model():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Dropout(0.2, input_shape=(8,)))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compile model\n",
        "    sgd = SGD(learning_rate=0.1, momentum=0.9)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_model, epochs=50, batch_size=64, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "results = cross_val_score(pipeline, X, encoded_Y)\n",
        "print(\"Visible: %.2f%% (%.2f%%)\" % (results.mean() * 100, results.std() * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYjOqcjSfVD7",
        "outputId": "9c6217a4-f630-4da8-eec6-014720810ab5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/regularization/dropout.py:42: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/regularization/dropout.py:42: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/regularization/dropout.py:42: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/regularization/dropout.py:42: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/regularization/dropout.py:42: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visible: 88.54% (0.34%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show the application of Dropout on the hidden layer:"
      ],
      "metadata": {
        "id": "StcW_hwkpWCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import read_csv\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.constraints import MaxNorm\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Load dataset\n",
        "dataframe = read_csv(\"https://archive.ics.uci.edu/static/public/379/data.csv\")\n",
        "dataset = dataframe.values\n",
        "\n",
        "# Split into input (X) and output (Y) variables\n",
        "X = dataset[:, 0:8].astype(float)\n",
        "Y = dataset[:, 8]\n",
        "\n",
        "# Encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "encoded_Y = encoder.transform(Y)\n",
        "\n",
        "# Dropout in hidden layers with weight constraint\n",
        "def create_model():\n",
        "    # Create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, input_shape=(8,), activation='relu', kernel_constraint=MaxNorm(3)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(64, activation='relu', kernel_constraint=MaxNorm(3)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(32, activation='relu', kernel_constraint=MaxNorm(3)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compile model\n",
        "    sgd = SGD(learning_rate=0.1, momentum=0.9)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Define pipeline\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_model, epochs=50, batch_size=64, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "\n",
        "# Evaluate using k-fold cross validation\n",
        "results = cross_val_score(pipeline, X, encoded_Y)\n",
        "print(\"Hidden: %.2f%% (%.2f%%)\" % (results.mean() * 100, results.std() * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38SK4tWnpWPY",
        "outputId": "54f8bf41-980f-452e-b406-af026f4a33ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden: 88.17% (0.61%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show the application of a time-based learning rate schedule:"
      ],
      "metadata": {
        "id": "aYHb93Jrsbh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import read_csv\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import math\n",
        "\n",
        "# Load dataset\n",
        "dataframe = read_csv(\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv\")\n",
        "dataset = dataframe.values\n",
        "\n",
        "# Split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8].astype(float)\n",
        "Y = dataset[:,8]\n",
        "\n",
        "# Encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "Y = encoder.fit_transform(Y)\n",
        "\n",
        "# Time-based learning rate schedule\n",
        "def time_based_decay(epoch):\n",
        "    initial_lrate = 0.1\n",
        "    k = 0.1\n",
        "    lrate = initial_lrate * math.pow(1 - k, epoch)\n",
        "    return lrate\n",
        "\n",
        "# Create model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=(8,), activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile model with SGD optimizer\n",
        "sgd = SGD(learning_rate=0.1)\n",
        "model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "# Define learning rate scheduler\n",
        "lrs = LearningRateScheduler(time_based_decay)\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X, Y, validation_split=0.33, epochs=50, batch_size=32, verbose=2, callbacks=[lrs])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DjbjAxEsbNE",
        "outputId": "4d2fe875-4860-43bd-ac06-020572e6e818"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "17/17 - 2s - 111ms/step - accuracy: 0.5536 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.1000\n",
            "Epoch 2/50\n",
            "17/17 - 1s - 39ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0900\n",
            "Epoch 3/50\n",
            "17/17 - 0s - 5ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0810\n",
            "Epoch 4/50\n",
            "17/17 - 0s - 9ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0729\n",
            "Epoch 5/50\n",
            "17/17 - 0s - 10ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0656\n",
            "Epoch 6/50\n",
            "17/17 - 0s - 10ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0590\n",
            "Epoch 7/50\n",
            "17/17 - 0s - 7ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0531\n",
            "Epoch 8/50\n",
            "17/17 - 0s - 9ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0478\n",
            "Epoch 9/50\n",
            "17/17 - 0s - 8ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0430\n",
            "Epoch 10/50\n",
            "17/17 - 0s - 8ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0387\n",
            "Epoch 11/50\n",
            "17/17 - 0s - 7ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0349\n",
            "Epoch 12/50\n",
            "17/17 - 0s - 8ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0314\n",
            "Epoch 13/50\n",
            "17/17 - 0s - 10ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0282\n",
            "Epoch 14/50\n",
            "17/17 - 0s - 17ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0254\n",
            "Epoch 15/50\n",
            "17/17 - 0s - 8ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0229\n",
            "Epoch 16/50\n",
            "17/17 - 0s - 9ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0206\n",
            "Epoch 17/50\n",
            "17/17 - 0s - 19ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0185\n",
            "Epoch 18/50\n",
            "17/17 - 0s - 17ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0167\n",
            "Epoch 19/50\n",
            "17/17 - 0s - 13ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0150\n",
            "Epoch 20/50\n",
            "17/17 - 0s - 5ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0135\n",
            "Epoch 21/50\n",
            "17/17 - 0s - 8ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0122\n",
            "Epoch 22/50\n",
            "17/17 - 0s - 8ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0109\n",
            "Epoch 23/50\n",
            "17/17 - 0s - 9ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0098\n",
            "Epoch 24/50\n",
            "17/17 - 0s - 8ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0089\n",
            "Epoch 25/50\n",
            "17/17 - 0s - 8ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0080\n",
            "Epoch 26/50\n",
            "17/17 - 0s - 6ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0072\n",
            "Epoch 27/50\n",
            "17/17 - 0s - 8ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0065\n",
            "Epoch 28/50\n",
            "17/17 - 0s - 8ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0058\n",
            "Epoch 29/50\n",
            "17/17 - 0s - 7ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0052\n",
            "Epoch 30/50\n",
            "17/17 - 0s - 9ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0047\n",
            "Epoch 31/50\n",
            "17/17 - 0s - 7ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0042\n",
            "Epoch 32/50\n",
            "17/17 - 0s - 9ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0038\n",
            "Epoch 33/50\n",
            "17/17 - 0s - 7ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0034\n",
            "Epoch 34/50\n",
            "17/17 - 0s - 8ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0031\n",
            "Epoch 35/50\n",
            "17/17 - 0s - 8ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0028\n",
            "Epoch 36/50\n",
            "17/17 - 0s - 8ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0025\n",
            "Epoch 37/50\n",
            "17/17 - 0s - 10ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0023\n",
            "Epoch 38/50\n",
            "17/17 - 0s - 5ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0020\n",
            "Epoch 39/50\n",
            "17/17 - 0s - 8ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0018\n",
            "Epoch 40/50\n",
            "17/17 - 0s - 5ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0016\n",
            "Epoch 41/50\n",
            "17/17 - 0s - 9ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0015\n",
            "Epoch 42/50\n",
            "17/17 - 0s - 5ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0013\n",
            "Epoch 43/50\n",
            "17/17 - 0s - 5ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0012\n",
            "Epoch 44/50\n",
            "17/17 - 0s - 8ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 0.0011\n",
            "Epoch 45/50\n",
            "17/17 - 0s - 8ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 9.6977e-04\n",
            "Epoch 46/50\n",
            "17/17 - 0s - 7ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 8.7280e-04\n",
            "Epoch 47/50\n",
            "17/17 - 0s - 6ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 7.8552e-04\n",
            "Epoch 48/50\n",
            "17/17 - 0s - 8ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 7.0697e-04\n",
            "Epoch 49/50\n",
            "17/17 - 0s - 5ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 6.3627e-04\n",
            "Epoch 50/50\n",
            "17/17 - 0s - 5ms/step - accuracy: 0.6413 - loss: nan - val_accuracy: 0.6732 - val_loss: nan - learning_rate: 5.7264e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e06f5c3f7f0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show the application of a drop-based learning rate schedule:"
      ],
      "metadata": {
        "id": "4_OISFads-aq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import read_csv\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import math\n",
        "\n",
        "# Load dataset\n",
        "dataframe = read_csv(\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv\")\n",
        "dataset = dataframe.values\n",
        "\n",
        "# Split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8].astype(float)\n",
        "Y = dataset[:,8]\n",
        "\n",
        "# Encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "Y = encoder.fit_transform(Y)\n",
        "\n",
        "# Drop-based learning rate schedule\n",
        "def drop_based_decay(epoch):\n",
        "    initial_lrate = 0.1\n",
        "    drop = 0.5\n",
        "    epochs_drop = 10.0\n",
        "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
        "    return lrate\n",
        "\n",
        "# Create model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=(8,), activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile model with SGD optimizer\n",
        "sgd = SGD(learning_rate=0.1)\n",
        "model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "# Define learning rate scheduler\n",
        "lrs = LearningRateScheduler(drop_based_decay)\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X, Y, validation_split=0.33, epochs=50, batch_size=32, verbose=2, callbacks=[lrs])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWCcZkuJs-p6",
        "outputId": "315f16da-b3a6-483d-fff9-d722c6d9c71a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "17/17 - 2s - 112ms/step - accuracy: 0.5497 - loss: 1765.2778 - val_accuracy: 0.6693 - val_loss: 0.7160 - learning_rate: 0.1000\n",
            "Epoch 2/50\n",
            "17/17 - 1s - 43ms/step - accuracy: 0.6277 - loss: 27.9585 - val_accuracy: 0.6732 - val_loss: 0.6399 - learning_rate: 0.1000\n",
            "Epoch 3/50\n",
            "17/17 - 0s - 7ms/step - accuracy: 0.6413 - loss: 0.6544 - val_accuracy: 0.6732 - val_loss: 0.6345 - learning_rate: 0.1000\n",
            "Epoch 4/50\n",
            "17/17 - 0s - 9ms/step - accuracy: 0.6413 - loss: 0.6534 - val_accuracy: 0.6732 - val_loss: 0.6332 - learning_rate: 0.1000\n",
            "Epoch 5/50\n",
            "17/17 - 0s - 6ms/step - accuracy: 0.6413 - loss: 0.6532 - val_accuracy: 0.6732 - val_loss: 0.6389 - learning_rate: 0.1000\n",
            "Epoch 6/50\n",
            "17/17 - 0s - 8ms/step - accuracy: 0.6413 - loss: 0.6536 - val_accuracy: 0.6732 - val_loss: 0.6344 - learning_rate: 0.1000\n",
            "Epoch 7/50\n",
            "17/17 - 0s - 7ms/step - accuracy: 0.6413 - loss: 0.6530 - val_accuracy: 0.6732 - val_loss: 0.6328 - learning_rate: 0.1000\n",
            "Epoch 8/50\n",
            "17/17 - 0s - 7ms/step - accuracy: 0.6413 - loss: 0.6534 - val_accuracy: 0.6732 - val_loss: 0.6322 - learning_rate: 0.1000\n",
            "Epoch 9/50\n",
            "17/17 - 0s - 9ms/step - accuracy: 0.6413 - loss: 0.6533 - val_accuracy: 0.6732 - val_loss: 0.6368 - learning_rate: 0.1000\n",
            "Epoch 10/50\n",
            "17/17 - 0s - 5ms/step - accuracy: 0.6413 - loss: 0.6529 - val_accuracy: 0.6732 - val_loss: 0.6379 - learning_rate: 0.0500\n",
            "Epoch 11/50\n",
            "17/17 - 0s - 6ms/step - accuracy: 0.6413 - loss: 0.6532 - val_accuracy: 0.6732 - val_loss: 0.6393 - learning_rate: 0.0500\n",
            "Epoch 12/50\n",
            "17/17 - 0s - 7ms/step - accuracy: 0.6413 - loss: 0.6537 - val_accuracy: 0.6732 - val_loss: 0.6365 - learning_rate: 0.0500\n",
            "Epoch 13/50\n",
            "17/17 - 0s - 8ms/step - accuracy: 0.6413 - loss: 0.6528 - val_accuracy: 0.6732 - val_loss: 0.6347 - learning_rate: 0.0500\n",
            "Epoch 14/50\n",
            "17/17 - 0s - 8ms/step - accuracy: 0.6413 - loss: 0.6523 - val_accuracy: 0.6732 - val_loss: 0.6362 - learning_rate: 0.0500\n",
            "Epoch 15/50\n",
            "17/17 - 0s - 8ms/step - accuracy: 0.6413 - loss: 0.6525 - val_accuracy: 0.6732 - val_loss: 0.6376 - learning_rate: 0.0500\n",
            "Epoch 16/50\n",
            "17/17 - 0s - 9ms/step - accuracy: 0.6413 - loss: 0.6519 - val_accuracy: 0.6732 - val_loss: 0.6369 - learning_rate: 0.0500\n",
            "Epoch 17/50\n",
            "17/17 - 0s - 6ms/step - accuracy: 0.6413 - loss: 0.6516 - val_accuracy: 0.6732 - val_loss: 0.6378 - learning_rate: 0.0500\n",
            "Epoch 18/50\n",
            "17/17 - 0s - 8ms/step - accuracy: 0.6413 - loss: 0.6501 - val_accuracy: 0.6732 - val_loss: 0.6434 - learning_rate: 0.0500\n",
            "Epoch 19/50\n",
            "17/17 - 0s - 8ms/step - accuracy: 0.6491 - loss: 0.6479 - val_accuracy: 0.6732 - val_loss: 0.6441 - learning_rate: 0.0500\n",
            "Epoch 20/50\n",
            "17/17 - 0s - 7ms/step - accuracy: 0.6140 - loss: 0.6631 - val_accuracy: 0.6732 - val_loss: 0.6390 - learning_rate: 0.0250\n",
            "Epoch 21/50\n",
            "17/17 - 0s - 11ms/step - accuracy: 0.6413 - loss: 0.6541 - val_accuracy: 0.6732 - val_loss: 0.6380 - learning_rate: 0.0250\n",
            "Epoch 22/50\n",
            "17/17 - 0s - 17ms/step - accuracy: 0.6413 - loss: 0.6536 - val_accuracy: 0.6732 - val_loss: 0.6383 - learning_rate: 0.0250\n",
            "Epoch 23/50\n",
            "17/17 - 0s - 11ms/step - accuracy: 0.6413 - loss: 0.6538 - val_accuracy: 0.6732 - val_loss: 0.6386 - learning_rate: 0.0250\n",
            "Epoch 24/50\n",
            "17/17 - 0s - 12ms/step - accuracy: 0.6413 - loss: 0.6538 - val_accuracy: 0.6732 - val_loss: 0.6389 - learning_rate: 0.0250\n",
            "Epoch 25/50\n",
            "17/17 - 0s - 8ms/step - accuracy: 0.6413 - loss: 0.6540 - val_accuracy: 0.6732 - val_loss: 0.6393 - learning_rate: 0.0250\n",
            "Epoch 26/50\n",
            "17/17 - 0s - 18ms/step - accuracy: 0.6413 - loss: 0.6542 - val_accuracy: 0.6732 - val_loss: 0.6382 - learning_rate: 0.0250\n",
            "Epoch 27/50\n",
            "17/17 - 0s - 16ms/step - accuracy: 0.6413 - loss: 0.6537 - val_accuracy: 0.6732 - val_loss: 0.6373 - learning_rate: 0.0250\n",
            "Epoch 28/50\n",
            "17/17 - 0s - 8ms/step - accuracy: 0.6413 - loss: 0.6533 - val_accuracy: 0.6732 - val_loss: 0.6377 - learning_rate: 0.0250\n",
            "Epoch 29/50\n",
            "17/17 - 0s - 20ms/step - accuracy: 0.6413 - loss: 0.6535 - val_accuracy: 0.6732 - val_loss: 0.6368 - learning_rate: 0.0250\n",
            "Epoch 30/50\n",
            "17/17 - 0s - 9ms/step - accuracy: 0.6413 - loss: 0.6532 - val_accuracy: 0.6732 - val_loss: 0.6364 - learning_rate: 0.0125\n",
            "Epoch 31/50\n",
            "17/17 - 0s - 10ms/step - accuracy: 0.6413 - loss: 0.6531 - val_accuracy: 0.6732 - val_loss: 0.6361 - learning_rate: 0.0125\n",
            "Epoch 32/50\n",
            "17/17 - 0s - 13ms/step - accuracy: 0.6413 - loss: 0.6529 - val_accuracy: 0.6732 - val_loss: 0.6358 - learning_rate: 0.0125\n",
            "Epoch 33/50\n",
            "17/17 - 0s - 5ms/step - accuracy: 0.6413 - loss: 0.6528 - val_accuracy: 0.6732 - val_loss: 0.6355 - learning_rate: 0.0125\n",
            "Epoch 34/50\n",
            "17/17 - 0s - 8ms/step - accuracy: 0.6413 - loss: 0.6527 - val_accuracy: 0.6732 - val_loss: 0.6352 - learning_rate: 0.0125\n",
            "Epoch 35/50\n",
            "17/17 - 0s - 8ms/step - accuracy: 0.6413 - loss: 0.6527 - val_accuracy: 0.6732 - val_loss: 0.6355 - learning_rate: 0.0125\n",
            "Epoch 36/50\n",
            "17/17 - 0s - 8ms/step - accuracy: 0.6413 - loss: 0.6528 - val_accuracy: 0.6732 - val_loss: 0.6355 - learning_rate: 0.0125\n",
            "Epoch 37/50\n",
            "17/17 - 0s - 5ms/step - accuracy: 0.6413 - loss: 0.6535 - val_accuracy: 0.6732 - val_loss: 0.6345 - learning_rate: 0.0125\n",
            "Epoch 38/50\n",
            "17/17 - 0s - 5ms/step - accuracy: 0.6413 - loss: 0.6514 - val_accuracy: 0.6772 - val_loss: 0.6320 - learning_rate: 0.0125\n",
            "Epoch 39/50\n",
            "17/17 - 0s - 8ms/step - accuracy: 0.6589 - loss: 0.6404 - val_accuracy: 0.6732 - val_loss: 0.6351 - learning_rate: 0.0125\n",
            "Epoch 40/50\n",
            "17/17 - 0s - 5ms/step - accuracy: 0.6413 - loss: 0.6526 - val_accuracy: 0.6732 - val_loss: 0.6345 - learning_rate: 0.0063\n",
            "Epoch 41/50\n",
            "17/17 - 0s - 8ms/step - accuracy: 0.6413 - loss: 0.6523 - val_accuracy: 0.6732 - val_loss: 0.6353 - learning_rate: 0.0063\n",
            "Epoch 42/50\n",
            "17/17 - 0s - 9ms/step - accuracy: 0.6413 - loss: 0.6528 - val_accuracy: 0.6732 - val_loss: 0.6347 - learning_rate: 0.0063\n",
            "Epoch 43/50\n",
            "17/17 - 0s - 5ms/step - accuracy: 0.6413 - loss: 0.6524 - val_accuracy: 0.6732 - val_loss: 0.6342 - learning_rate: 0.0063\n",
            "Epoch 44/50\n",
            "17/17 - 0s - 10ms/step - accuracy: 0.6413 - loss: 0.6522 - val_accuracy: 0.6732 - val_loss: 0.6341 - learning_rate: 0.0063\n",
            "Epoch 45/50\n",
            "17/17 - 0s - 6ms/step - accuracy: 0.6413 - loss: 0.6521 - val_accuracy: 0.6732 - val_loss: 0.6338 - learning_rate: 0.0063\n",
            "Epoch 46/50\n",
            "17/17 - 0s - 13ms/step - accuracy: 0.6413 - loss: 0.6520 - val_accuracy: 0.6732 - val_loss: 0.6336 - learning_rate: 0.0063\n",
            "Epoch 47/50\n",
            "17/17 - 0s - 10ms/step - accuracy: 0.6413 - loss: 0.6519 - val_accuracy: 0.6732 - val_loss: 0.6335 - learning_rate: 0.0063\n",
            "Epoch 48/50\n",
            "17/17 - 0s - 19ms/step - accuracy: 0.6413 - loss: 0.6519 - val_accuracy: 0.6732 - val_loss: 0.6334 - learning_rate: 0.0063\n",
            "Epoch 49/50\n",
            "17/17 - 0s - 18ms/step - accuracy: 0.6413 - loss: 0.6519 - val_accuracy: 0.6732 - val_loss: 0.6332 - learning_rate: 0.0063\n",
            "Epoch 50/50\n",
            "17/17 - 0s - 15ms/step - accuracy: 0.6413 - loss: 0.6519 - val_accuracy: 0.6732 - val_loss: 0.6332 - learning_rate: 0.0031\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e06f62cca90>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this activity its hard to fix the code but at the same time it was enjoying I learn a lot of in this activity like the basic principles of neural network modeling and training throughout this set of assignments. I was able to apply the model that checkpointing to track progress, Models get saved and loaded in many ways. You can check out training info to spot trends. I tweak learning rates and use dropout to stop overfitting. This helps the model learn better. These tricks show I know how to make models work well.\n",
        "\n"
      ],
      "metadata": {
        "id": "NnSI3umPthn6"
      }
    }
  ]
}